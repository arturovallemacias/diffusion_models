{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjiPkkeOxghjAHIMfEHglk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arturovallemacias/diffusion_models/blob/main/denoise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USERNAME=\"arturovallemacias\"\n",
        "TOKEN=\"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\"\n",
        "\n",
        "# Configura el helper de credenciales para almacenarlas en caché\n",
        "!git config --global credential.helper store\n",
        "\n",
        "# Clona el repositorio utilizando el token personal\n",
        "!git clone https://$USERNAME:$TOKEN@github.com/$USERNAME/diffusion_models.git\n",
        "\n",
        "\n",
        "!git config --global user.email \"arturo_valle@live.com\"\n",
        "!git config --global user.name \"arturovallemacias\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERGNQhDlFSnM",
        "outputId": "c0b125e3-f392-43bb-83d1-1846b10e6508"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusion_models'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 101 (delta 31), reused 25 (delta 25), pack-reused 66\u001b[K\n",
            "Receiving objects: 100% (101/101), 4.32 MiB | 10.04 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/diffusion_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UssCnbAYF8fr",
        "outputId": "930107a1-d444-4e75-891c-56f11e8260db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diffusion_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from keras.datasets.mnist import load_data\n",
        "\n",
        "from unet import UNet\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "M1qQUZaKFBo0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(precision=6, sci_mode=False)\n",
        "np.set_printoptions(precision=9, suppress=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "VsENjUHpA6n3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(trainX, trainy), (testX, testy) = load_data()\n",
        "trainX = np.float32(trainX) / 255.\n",
        "testX = np.float32(testX) / 255."
      ],
      "metadata": {
        "id": "MLT4XmgJGBKr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_batch(batch_size, device):\n",
        "    indices = torch.randperm(trainX.shape[0])[:batch_size]\n",
        "    data = torch.from_numpy(trainX[indices]).unsqueeze(1).to(device)\n",
        "    return torch.nn.functional.interpolate(data, 32)"
      ],
      "metadata": {
        "id": "oT16dz_NGXlL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionModel():\n",
        "\n",
        "    def __init__(self, T : int, model : nn.Module, device : str):\n",
        "\n",
        "        self.T = T\n",
        "\n",
        "        self.function_approximator = model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "        self.beta = torch.linspace(1e-4, 0.02, T).to(device)\n",
        "\n",
        "        self.alpha = 1. - self.beta\n",
        "\n",
        "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
        "\n",
        "    def training(self, batch_size, optimizer):\n",
        "        \"\"\"\n",
        "        Algorithm 1 in Denoising Diffusion Probabilistic Models\n",
        "        \"\"\"\n",
        "\n",
        "        x0 = sample_batch(batch_size, self.device)\n",
        "\n",
        "        t = torch.randint(1, self.T + 1, (batch_size,), device=self.device, dtype=torch.long)\n",
        "\n",
        "        eps = torch.randn_like(x0)\n",
        "\n",
        "        alpha_bar_t = self.alpha_bar[t-1].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "\n",
        "\n",
        "        eps_predicted = self.function_approximator(torch.sqrt(\n",
        "            alpha_bar_t) * x0 + torch.sqrt(1 - alpha_bar_t) * eps, t-1)\n",
        "\n",
        "\n",
        "        loss = nn.functional.mse_loss(eps, eps_predicted)\n",
        "        #optimizer.zero_grad()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "\n",
        "        #return loss.item()\n",
        "        return alpha_bar_t\n",
        "    @torch.no_grad()\n",
        "    def sampling(self, n_samples=1, image_channels=1, img_size=(32, 32), use_tqdm=True):\n",
        "\n",
        "        x = torch.randn((n_samples, image_channels, img_size[0], img_size[1]),\n",
        "                         device=self.device)\n",
        "\n",
        "        progress_bar = tqdm if use_tqdm else lambda x : x\n",
        "        for t in progress_bar(range(self.T, 0, -1)):\n",
        "            z = torch.randn_like(x) if t > 1 else torch.zeros_like(x)\n",
        "\n",
        "            t = torch.ones(n_samples, dtype=torch.long, device=self.device) * t\n",
        "\n",
        "            beta_t = self.beta[t-1].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "            alpha_t = self.alpha[t-1].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "            alpha_bar_t = self.alpha_bar[t-1].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "            mean = 1 / torch.sqrt(alpha_t) * (x - ((1 - alpha_t) / torch.sqrt(\n",
        "                1 - alpha_bar_t)) * self.function_approximator(x, t-1))\n",
        "            sigma = torch.sqrt(beta_t)\n",
        "            x = mean + sigma * z\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "3y3iXpM28w9W"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 64\n",
        "model = UNet()\n",
        "device = \"cpu\"\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "diffusion_model = DiffusionModel(1000, model, device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-y0YJJMM9G13"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss = []\n",
        "for epoch in tqdm(range(1)):\n",
        "    sel = diffusion_model.training(batch_size, optimizer)\n",
        "\n",
        "    print(sel)\n",
        "    #training_loss.append(loss)\n",
        "\n",
        "    #if epoch % 100 == 0:\n",
        "        #plt.plot(training_loss)\n",
        "        #plt.savefig('training_loss.png')\n",
        "        #plt.close()\n",
        "\n",
        "        #plt.plot(training_loss[-1000:])\n",
        "        #plt.savefig('training_loss_cropped.png')\n",
        "        #plt.close()\n",
        "\n",
        "    #if epoch % 5000 == 0:\n",
        "        #nb_images=81\n",
        "        #samples = diffusion_model.sampling(n_samples=nb_images, use_tqdm=False)\n",
        "        #plt.figure(figsize=(17, 17))\n",
        "        #for i in range(nb_images):\n",
        "            #plt.subplot(9, 9, 1 + i)\n",
        "            #plt.axis('off')\n",
        "            #plt.imshow(samples[i].squeeze(0).clip(0, 1).data.cpu().numpy(), cmap='gray')\n",
        "        #plt.savefig(f'samples_epoch_{epoch}.png')\n",
        "        #plt.close()\n",
        "\n",
        "        #torch.save(model.cpu(), f'model_paper2_epoch_{epoch}')\n",
        "        #model.cuda()"
      ],
      "metadata": {
        "id": "WmTPalyyBvT_",
        "outputId": "2396c700-e6bd-4bd6-950c-ef92e8e13ca2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:16<00:00, 16.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.sqrt(alpha_bar_t) tensor([[[[0.789886]]],\n",
            "\n",
            "\n",
            "        [[[0.699818]]],\n",
            "\n",
            "\n",
            "        [[[0.703553]]],\n",
            "\n",
            "\n",
            "        [[[0.199903]]],\n",
            "\n",
            "\n",
            "        [[[0.032418]]],\n",
            "\n",
            "\n",
            "        [[[0.034070]]],\n",
            "\n",
            "\n",
            "        [[[0.010005]]],\n",
            "\n",
            "\n",
            "        [[[0.074984]]],\n",
            "\n",
            "\n",
            "        [[[0.160871]]],\n",
            "\n",
            "\n",
            "        [[[0.178060]]],\n",
            "\n",
            "\n",
            "        [[[0.122830]]],\n",
            "\n",
            "\n",
            "        [[[0.299103]]],\n",
            "\n",
            "\n",
            "        [[[0.709140]]],\n",
            "\n",
            "\n",
            "        [[[0.068712]]],\n",
            "\n",
            "\n",
            "        [[[0.293251]]],\n",
            "\n",
            "\n",
            "        [[[0.351512]]],\n",
            "\n",
            "\n",
            "        [[[0.243704]]],\n",
            "\n",
            "\n",
            "        [[[0.066228]]],\n",
            "\n",
            "\n",
            "        [[[0.267768]]],\n",
            "\n",
            "\n",
            "        [[[0.539724]]],\n",
            "\n",
            "\n",
            "        [[[0.947110]]],\n",
            "\n",
            "\n",
            "        [[[0.123630]]],\n",
            "\n",
            "\n",
            "        [[[0.154154]]],\n",
            "\n",
            "\n",
            "        [[[0.008733]]],\n",
            "\n",
            "\n",
            "        [[[0.461575]]],\n",
            "\n",
            "\n",
            "        [[[0.903800]]],\n",
            "\n",
            "\n",
            "        [[[0.972809]]],\n",
            "\n",
            "\n",
            "        [[[0.679139]]],\n",
            "\n",
            "\n",
            "        [[[0.789886]]],\n",
            "\n",
            "\n",
            "        [[[0.837689]]],\n",
            "\n",
            "\n",
            "        [[[0.148562]]],\n",
            "\n",
            "\n",
            "        [[[0.997579]]],\n",
            "\n",
            "\n",
            "        [[[0.039779]]],\n",
            "\n",
            "\n",
            "        [[[0.079415]]],\n",
            "\n",
            "\n",
            "        [[[0.121244]]],\n",
            "\n",
            "\n",
            "        [[[0.633449]]],\n",
            "\n",
            "\n",
            "        [[[0.753016]]],\n",
            "\n",
            "\n",
            "        [[[0.008733]]],\n",
            "\n",
            "\n",
            "        [[[0.921065]]],\n",
            "\n",
            "\n",
            "        [[[0.008234]]],\n",
            "\n",
            "\n",
            "        [[[0.391199]]],\n",
            "\n",
            "\n",
            "        [[[0.781259]]],\n",
            "\n",
            "\n",
            "        [[[0.007239]]],\n",
            "\n",
            "\n",
            "        [[[0.465212]]],\n",
            "\n",
            "\n",
            "        [[[0.942071]]],\n",
            "\n",
            "\n",
            "        [[[0.022862]]],\n",
            "\n",
            "\n",
            "        [[[0.772534]]],\n",
            "\n",
            "\n",
            "        [[[0.646833]]],\n",
            "\n",
            "\n",
            "        [[[0.954734]]],\n",
            "\n",
            "\n",
            "        [[[0.049649]]],\n",
            "\n",
            "\n",
            "        [[[0.720253]]],\n",
            "\n",
            "\n",
            "        [[[0.595101]]],\n",
            "\n",
            "\n",
            "        [[[0.237274]]],\n",
            "\n",
            "\n",
            "        [[[0.008315]]],\n",
            "\n",
            "\n",
            "        [[[0.061020]]],\n",
            "\n",
            "\n",
            "        [[[0.007760]]],\n",
            "\n",
            "\n",
            "        [[[0.315543]]],\n",
            "\n",
            "\n",
            "        [[[0.097932]]],\n",
            "\n",
            "\n",
            "        [[[0.155101]]],\n",
            "\n",
            "\n",
            "        [[[0.019681]]],\n",
            "\n",
            "\n",
            "        [[[0.009169]]],\n",
            "\n",
            "\n",
            "        [[[0.021883]]],\n",
            "\n",
            "\n",
            "        [[[0.071792]]],\n",
            "\n",
            "\n",
            "        [[[0.297634]]]])\n",
            "x0) tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
            "torch.sqrt(1 - alpha_bar_t)) tensor([[[[0.613254]]],\n",
            "\n",
            "\n",
            "        [[[0.714321]]],\n",
            "\n",
            "\n",
            "        [[[0.710643]]],\n",
            "\n",
            "\n",
            "        [[[0.979816]]],\n",
            "\n",
            "\n",
            "        [[[0.999474]]],\n",
            "\n",
            "\n",
            "        [[[0.999419]]],\n",
            "\n",
            "\n",
            "        [[[0.999950]]],\n",
            "\n",
            "\n",
            "        [[[0.997185]]],\n",
            "\n",
            "\n",
            "        [[[0.986975]]],\n",
            "\n",
            "\n",
            "        [[[0.984020]]],\n",
            "\n",
            "\n",
            "        [[[0.992428]]],\n",
            "\n",
            "\n",
            "        [[[0.954221]]],\n",
            "\n",
            "\n",
            "        [[[0.705068]]],\n",
            "\n",
            "\n",
            "        [[[0.997637]]],\n",
            "\n",
            "\n",
            "        [[[0.956035]]],\n",
            "\n",
            "\n",
            "        [[[0.936183]]],\n",
            "\n",
            "\n",
            "        [[[0.969850]]],\n",
            "\n",
            "\n",
            "        [[[0.997805]]],\n",
            "\n",
            "\n",
            "        [[[0.963483]]],\n",
            "\n",
            "\n",
            "        [[[0.841842]]],\n",
            "\n",
            "\n",
            "        [[[0.320908]]],\n",
            "\n",
            "\n",
            "        [[[0.992328]]],\n",
            "\n",
            "\n",
            "        [[[0.988047]]],\n",
            "\n",
            "\n",
            "        [[[0.999962]]],\n",
            "\n",
            "\n",
            "        [[[0.887101]]],\n",
            "\n",
            "\n",
            "        [[[0.427956]]],\n",
            "\n",
            "\n",
            "        [[[0.231607]]],\n",
            "\n",
            "\n",
            "        [[[0.734009]]],\n",
            "\n",
            "\n",
            "        [[[0.613254]]],\n",
            "\n",
            "\n",
            "        [[[0.546147]]],\n",
            "\n",
            "\n",
            "        [[[0.988903]]],\n",
            "\n",
            "\n",
            "        [[[0.069548]]],\n",
            "\n",
            "\n",
            "        [[[0.999209]]],\n",
            "\n",
            "\n",
            "        [[[0.996842]]],\n",
            "\n",
            "\n",
            "        [[[0.992623]]],\n",
            "\n",
            "\n",
            "        [[[0.773785]]],\n",
            "\n",
            "\n",
            "        [[[0.658002]]],\n",
            "\n",
            "\n",
            "        [[[0.999962]]],\n",
            "\n",
            "\n",
            "        [[[0.389410]]],\n",
            "\n",
            "\n",
            "        [[[0.999966]]],\n",
            "\n",
            "\n",
            "        [[[0.920306]]],\n",
            "\n",
            "\n",
            "        [[[0.624206]]],\n",
            "\n",
            "\n",
            "        [[[0.999974]]],\n",
            "\n",
            "\n",
            "        [[[0.885199]]],\n",
            "\n",
            "\n",
            "        [[[0.335414]]],\n",
            "\n",
            "\n",
            "        [[[0.999739]]],\n",
            "\n",
            "\n",
            "        [[[0.634973]]],\n",
            "\n",
            "\n",
            "        [[[0.762631]]],\n",
            "\n",
            "\n",
            "        [[[0.297460]]],\n",
            "\n",
            "\n",
            "        [[[0.998767]]],\n",
            "\n",
            "\n",
            "        [[[0.693712]]],\n",
            "\n",
            "\n",
            "        [[[0.803651]]],\n",
            "\n",
            "\n",
            "        [[[0.971443]]],\n",
            "\n",
            "\n",
            "        [[[0.999965]]],\n",
            "\n",
            "\n",
            "        [[[0.998137]]],\n",
            "\n",
            "\n",
            "        [[[0.999970]]],\n",
            "\n",
            "\n",
            "        [[[0.948911]]],\n",
            "\n",
            "\n",
            "        [[[0.995193]]],\n",
            "\n",
            "\n",
            "        [[[0.987899]]],\n",
            "\n",
            "\n",
            "        [[[0.999806]]],\n",
            "\n",
            "\n",
            "        [[[0.999958]]],\n",
            "\n",
            "\n",
            "        [[[0.999761]]],\n",
            "\n",
            "\n",
            "        [[[0.997420]]],\n",
            "\n",
            "\n",
            "        [[[0.954680]]]])\n",
            "tensor([[[[    0.623919]]],\n",
            "\n",
            "\n",
            "        [[[    0.489745]]],\n",
            "\n",
            "\n",
            "        [[[    0.494987]]],\n",
            "\n",
            "\n",
            "        [[[    0.039961]]],\n",
            "\n",
            "\n",
            "        [[[    0.001051]]],\n",
            "\n",
            "\n",
            "        [[[    0.001161]]],\n",
            "\n",
            "\n",
            "        [[[    0.000100]]],\n",
            "\n",
            "\n",
            "        [[[    0.005623]]],\n",
            "\n",
            "\n",
            "        [[[    0.025879]]],\n",
            "\n",
            "\n",
            "        [[[    0.031705]]],\n",
            "\n",
            "\n",
            "        [[[    0.015087]]],\n",
            "\n",
            "\n",
            "        [[[    0.089463]]],\n",
            "\n",
            "\n",
            "        [[[    0.502879]]],\n",
            "\n",
            "\n",
            "        [[[    0.004721]]],\n",
            "\n",
            "\n",
            "        [[[    0.085996]]],\n",
            "\n",
            "\n",
            "        [[[    0.123561]]],\n",
            "\n",
            "\n",
            "        [[[    0.059391]]],\n",
            "\n",
            "\n",
            "        [[[    0.004386]]],\n",
            "\n",
            "\n",
            "        [[[    0.071700]]],\n",
            "\n",
            "\n",
            "        [[[    0.291302]]],\n",
            "\n",
            "\n",
            "        [[[    0.897018]]],\n",
            "\n",
            "\n",
            "        [[[    0.015284]]],\n",
            "\n",
            "\n",
            "        [[[    0.023763]]],\n",
            "\n",
            "\n",
            "        [[[    0.000076]]],\n",
            "\n",
            "\n",
            "        [[[    0.213051]]],\n",
            "\n",
            "\n",
            "        [[[    0.816854]]],\n",
            "\n",
            "\n",
            "        [[[    0.946358]]],\n",
            "\n",
            "\n",
            "        [[[    0.461230]]],\n",
            "\n",
            "\n",
            "        [[[    0.623919]]],\n",
            "\n",
            "\n",
            "        [[[    0.701724]]],\n",
            "\n",
            "\n",
            "        [[[    0.022071]]],\n",
            "\n",
            "\n",
            "        [[[    0.995163]]],\n",
            "\n",
            "\n",
            "        [[[    0.001582]]],\n",
            "\n",
            "\n",
            "        [[[    0.006307]]],\n",
            "\n",
            "\n",
            "        [[[    0.014700]]],\n",
            "\n",
            "\n",
            "        [[[    0.401257]]],\n",
            "\n",
            "\n",
            "        [[[    0.567034]]],\n",
            "\n",
            "\n",
            "        [[[    0.000076]]],\n",
            "\n",
            "\n",
            "        [[[    0.848360]]],\n",
            "\n",
            "\n",
            "        [[[    0.000068]]],\n",
            "\n",
            "\n",
            "        [[[    0.153036]]],\n",
            "\n",
            "\n",
            "        [[[    0.610366]]],\n",
            "\n",
            "\n",
            "        [[[    0.000052]]],\n",
            "\n",
            "\n",
            "        [[[    0.216422]]],\n",
            "\n",
            "\n",
            "        [[[    0.887497]]],\n",
            "\n",
            "\n",
            "        [[[    0.000523]]],\n",
            "\n",
            "\n",
            "        [[[    0.596809]]],\n",
            "\n",
            "\n",
            "        [[[    0.418393]]],\n",
            "\n",
            "\n",
            "        [[[    0.911517]]],\n",
            "\n",
            "\n",
            "        [[[    0.002465]]],\n",
            "\n",
            "\n",
            "        [[[    0.518764]]],\n",
            "\n",
            "\n",
            "        [[[    0.354145]]],\n",
            "\n",
            "\n",
            "        [[[    0.056299]]],\n",
            "\n",
            "\n",
            "        [[[    0.000069]]],\n",
            "\n",
            "\n",
            "        [[[    0.003723]]],\n",
            "\n",
            "\n",
            "        [[[    0.000060]]],\n",
            "\n",
            "\n",
            "        [[[    0.099567]]],\n",
            "\n",
            "\n",
            "        [[[    0.009591]]],\n",
            "\n",
            "\n",
            "        [[[    0.024056]]],\n",
            "\n",
            "\n",
            "        [[[    0.000387]]],\n",
            "\n",
            "\n",
            "        [[[    0.000084]]],\n",
            "\n",
            "\n",
            "        [[[    0.000479]]],\n",
            "\n",
            "\n",
            "        [[[    0.005154]]],\n",
            "\n",
            "\n",
            "        [[[    0.088586]]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}