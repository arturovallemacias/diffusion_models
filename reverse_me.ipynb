{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOV9bvTbF8V72JurGURUlJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arturovallemacias/diffusion_models/blob/main/reverse_me.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzx7K0GriHgK",
        "outputId": "ea1429c9-e295-4c5c-9a6d-8a13b92b6201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusion_models'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 24 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (24/24), 1.28 MiB | 15.46 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "USERNAME=\"arturovallemacias\"\n",
        "TOKEN=\"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\"\n",
        "\n",
        "# Configura el helper de credenciales para almacenarlas en cachÃ©\n",
        "!git config --global credential.helper store\n",
        "\n",
        "# Clona el repositorio utilizando el token personal\n",
        "!git clone https://$USERNAME:$TOKEN@github.com/$USERNAME/diffusion_models.git\n",
        "\n",
        "\n",
        "!git config --global user.email \"arturo_valle@live.com\"\n",
        "!git config --global user.name \"arturovallemacias\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)\n",
        "\n",
        "from helper_functions import plot_predictions, plot_decision_boundary"
      ],
      "metadata": {
        "id": "cOjKyouYrklE",
        "outputId": "c217c0e8-5fe9-47c1-dd51-73ff56c1f062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading helper_functions.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_swiss_roll"
      ],
      "metadata": {
        "id": "PD3u_iaopE_s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_batch(batch_size, device='cpu'):\n",
        "    data, _ = make_swiss_roll(batch_size)\n",
        "    data = data[:, [2, 0]] / 10\n",
        "    data = data * np.array([1, -1])\n",
        "    return torch.from_numpy(data).to(device)"
      ],
      "metadata": {
        "id": "MFDLU1VppHOk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, N=40, data_dim=2, hidden_dim=64):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.network_head = nn.Sequential(nn.Linear(data_dim, hidden_dim),\n",
        "                                          nn.ReLU(),\n",
        "                                          nn.Linear(hidden_dim, hidden_dim),\n",
        "                                          nn.ReLU(),)\n",
        "\n",
        "        self.network_tail = nn.ModuleList([nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n",
        "                                                         nn.ReLU(),\n",
        "                                                         nn.Linear(hidden_dim, data_dim * 2),) for t in range(N)])\n",
        "\n",
        "    def forward(self, x, t):\n",
        "\n",
        "        h = self.network_head(x) # [batch_size, hidden_dim]\n",
        "        tmp = self.network_tail[t](h) # [batch_size, data_dim * 2]\n",
        "\n",
        "        mu, h = torch.chunk(tmp, 2, dim=1)\n",
        "        var = torch.exp(h)\n",
        "        std = torch.sqrt(var)\n",
        "\n",
        "        return mu, std"
      ],
      "metadata": {
        "id": "MGhxtVzoM7Du"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP()\n",
        "t = 5\n",
        "x = torch.randn((64, 2))\n",
        "mu, std = model(x, t)\n"
      ],
      "metadata": {
        "id": "jmLELvvYN7bd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mu.shape)\n",
        "print(std.shape)"
      ],
      "metadata": {
        "id": "yiOGNCYON-v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionModel():\n",
        "\n",
        "    def __init__(self, T, model: nn.Module, dim=2):\n",
        "\n",
        "        self.betas = torch.sigmoid(torch.linspace(-18, 10, T)) * (3e-1 - 1e-5) + 1e-5\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.alphas_bar = torch.cumprod(self.alphas, 0)\n",
        "\n",
        "        self.T = T\n",
        "        self.model = model\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward_process(self, x0, t):\n",
        "        \"\"\"\n",
        "        :param t: Number of diffusion steps\n",
        "        \"\"\"\n",
        "\n",
        "        assert t > 0, 't should be greater than 0'\n",
        "        assert self.T <= self.T, f't should be lower or equal than {self.T}'\n",
        "\n",
        "        t = t -1 # Because we start indexing at 0\n",
        "\n",
        "        mu = torch.sqrt(self.alphas_bar[t]) * x0\n",
        "        std = torch.sqrt(1 - self.alphas_bar[t])\n",
        "        epsilon = torch.randn_like(x0)\n",
        "\n",
        "        return mu + epsilon * std # data ~ N(mu, std)\n",
        "\n",
        "    def reverse_process(self, xt, t):\n",
        "        \"\"\"\n",
        "        :param t: Number of diffusion steps\n",
        "        \"\"\"\n",
        "\n",
        "        assert t > 0, 't should be greater than 0'\n",
        "        assert self.T <= self.T, f't should be lower or equal than {self.T}'\n",
        "\n",
        "        t = t - 1 # Because we start indexing at 0\n",
        "\n",
        "        mu, std = self.model(xt, t)\n",
        "        epsilon = torch.randn_like(xt)\n",
        "\n",
        "        return mu + epsilon * std # data ~ N(mu, std)\n",
        "\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "\n",
        "        noise = torch.randn((batch_size, self.dim))\n",
        "        x = noise\n",
        "\n",
        "        samples = [x]\n",
        "        for t in range(self.T, 0, -1):\n",
        "\n",
        "            if not (t == 1):\n",
        "                x = self.reverse_process(x, t)\n",
        "\n",
        "\n",
        "            samples.append(x)\n",
        "\n",
        "        return samples[::-1]\n"
      ],
      "metadata": {
        "id": "f3J9r6acpKcE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = torch.load(\"model_paper1\")"
      ],
      "metadata": {
        "id": "1VTUNx402jZ8",
        "outputId": "cc7f9827-d0b0-4f36-f631-9e7edb00c055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4edf808f6a1f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_paper1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_paper1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = sample_batch(3_000)\n",
        "mlp_model = torch.load(\"model_paper1\")\n",
        "model = DiffusionModel(40, model)\n",
        "xT = model.forward_process(x0, 20)"
      ],
      "metadata": {
        "id": "z6AZ-jwQpMJ1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = model.sample(1000)"
      ],
      "metadata": {
        "id": "jW6J5-nhPs52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = 40\n",
        "plt.scatter(samples[t][:, 0].data.numpy(), samples[t][:, 1].data.numpy())"
      ],
      "metadata": {
        "id": "7CVMbHq7NbGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xT.mean(0))\n",
        "print(xT.std(0))"
      ],
      "metadata": {
        "id": "2lImm5jKNpkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fontsize = 14\n",
        "fig = plt.figure(figsize=(10, 3))\n",
        "\n",
        "data = [x0, model.forward_process(x0, 20), model.forward_process(x0, 40)]\n",
        "for i in range(3):\n",
        "\n",
        "    plt.subplot(1, 3, 1+i)\n",
        "    plt.scatter(data[i][:, 0].data.numpy(), data[i][:, 1].data.numpy(), alpha=0.1)\n",
        "    plt.xlim([-2, 2])\n",
        "    plt.ylim([-2, 2])\n",
        "    plt.gca().set_aspect('equal')\n",
        "\n",
        "    if i == 0: plt.ylabel(r'$q(\\mathbf{x}^{(0..T)})$', fontsize=fontsize)\n",
        "    if i == 0: plt.title(r'$t=0$', fontsize=fontsize)\n",
        "    if i == 1: plt.title(r'$t=\\frac{T}{2}$', fontsize=fontsize)\n",
        "    if i == 2: plt.title(r'$t=T$', fontsize=fontsize)\n",
        "plt.savefig('forward_process.png', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "z1i8LV8JNunV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}